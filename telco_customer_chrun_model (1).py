# -*- coding: utf-8 -*-
"""Telco Customer Chrun Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ERj-4NSA66txmC_aFwOuYzZCvzlsx9Bc
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, roc_auc_score, classification_report,
                             confusion_matrix, ConfusionMatrixDisplay, roc_curve)

import joblib

# 1. Load Data

df = pd.read_csv("telco customer chrun dataset.csv")

# 2. Preprocessing
# Remove duplicates
df.drop_duplicates(inplace=True)

# Convert target to binary
df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})

# Handle missing values
df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors='coerce')
df.fillna(df.median(numeric_only=True), inplace=True)

# Drop customerID
if "customerID" in df.columns:
    df.drop("customerID", axis=1, inplace=True)

# Encode categorical variables
df = pd.get_dummies(df, drop_first=True)

# 3. Split & Scale

X = df.drop("Churn", axis=1)
y = df["Churn"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)


# 4. Train with GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'bootstrap': [True, False]
}
rf = RandomForestClassifier(random_state=42, class_weight='balanced')
grid_search = GridSearchCV(rf, param_grid, cv=3, n_jobs=-1, scoring='accuracy')
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

# 5. Evaluation

y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)[:, 1]

print("Accuracy:", accuracy_score(y_test, y_pred)*100)
print("ROC AUC:", roc_auc_score(y_test, y_prob)*100)
print("Classification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.title("Confusion Matrix")
plt.show()

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_prob)
plt.plot(fpr, tpr, label='ROC Curve')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

# Cross-Validation Score
cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='roc_auc')
print("Cross-Validated AUC Scores:", cv_scores)
print("Mean AUC:", cv_scores.mean())


# 6. Feature Importance

importances = best_model.feature_importances_
features = X.columns
feat_importance = pd.Series(importances, index=features).sort_values(ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=feat_importance[:10], y=feat_importance.index[:10])
plt.xlabel("Importance Score")
plt.ylabel("Feature")
plt.title("Top 10 Important Features for Churn Prediction")
plt.tight_layout()
plt.show()


# 7. EDA

sns.countplot(data=df, x='Churn')
plt.title('Churn Distribution')
plt.show()

sns.boxplot(data=df, x='Churn', y='MonthlyCharges')
plt.title('Monthly Charges by Churn Status')
plt.show()

sns.histplot(data=df, x='tenure', hue='Churn', kde=True, multiple='stack')
plt.title('Tenure vs Churn')
plt.show()

plt.figure(figsize=(14, 6))
sns.heatmap(df.corr(numeric_only=True), annot=False, cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()


# 8. Save Model

joblib.dump(best_model, "churn_model.pkl")
joblib.dump(scaler, "scaler.pkl")